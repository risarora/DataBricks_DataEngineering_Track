# Fundamentals of the Databricks Lakehouse Platform
## Data Warehouse
<img width="739" alt="1yaxbDVrTn0gBSt7_unLW81SIoQxz04_C" src="https://user-images.githubusercontent.com/4485129/123216882-a07ccf00-d4e7-11eb-865b-7bfb749ba8bc.png">

## Data Lake
<img width="735" alt="jRYj_I9Hqzqgja7n_-OqHJoTOFyJ3EYcr" src="https://user-images.githubusercontent.com/4485129/123216966-b4c0cc00-d4e7-11eb-9e80-a35280e1ed83.png">

## LakeHouse

<img width="742" alt="LtkbtqJ6ie8Xetx6_NmThSN17hhStRXwT" src="https://user-images.githubusercontent.com/4485129/123217345-18e39000-d4e8-11eb-9f74-fd3dd1357366.png">

### Data lakehouses have the following key features:
* Transaction support to ensure that multiple parties can concurrently read or write data
* Data schema enforcement to ensure data integrity (writes to a table are rejected if they do not match the tableâ€™s schema)
* Governance and auditioning mechanisms to make sure you can see how data is being used 
* BI support so that BI tools can work directly on source data - this reduces data staleness.
* Storage is decoupled from compute, which means that it is easier for your system to scale to more concurrent users and data sizes.
* Openness - Storage formats used are open and standard. Plus, APIs and various other tools make it easy for team members to access data directly.
* Support for all data types - structured, unstructured, semi-structured
* End-to-end streaming so that real-time reporting and real-time data can be integrated into data analytics processes just as existing data is
* Support for diverse workloads, including data engineering, data science, machine learning, and SQL analytics - all on the same data repository.

